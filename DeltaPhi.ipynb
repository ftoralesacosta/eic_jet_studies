{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62e08dca-9d7b-434b-bb40-d77ceb82d6ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.18/00\n"
     ]
    }
   ],
   "source": [
    "import ROOT\n",
    "import numpy as np\n",
    "from ROOT import TGraphErrors\n",
    "from ROOT import TVectorT\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import ticker\n",
    "from root_np_functions import *\n",
    "from plotting_functions import *\n",
    "\n",
    "from resolutions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a762c4b-22cd-4dcc-90ec-3e9310573f44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "def gauss(x, a, x0, sigma):\n",
    "    return a * np.exp(-(x - x0) ** 2 / (2 * sigma ** 2))\n",
    "\n",
    "def double_gauss(x,a,mu0,sigma0,b,mu1,sigma1):\n",
    "    return (a * np.exp(-(x - mu0) ** 2 / (2 * sigma0 ** 2)) +\n",
    "            b * np.exp(-(x - mu1) ** 2 / (2 * sigma1 ** 2)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0967a2-f258-4fd0-acfc-a5705bafb637",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Compare Charged Truth and Reco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07cbc87f-e073-4dbc-952a-2c223b9bf19c",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "get_th1_binning_np() takes 1 positional argument but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-591ff6efa56f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mROOT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprefixes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0mh1dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"edges\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh1dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"centers\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh1dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"widths\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_th1_binning_np\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"h1_eDelta_dph_p_et_bins_0_p_0_bin\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"eD_dph_histos\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0meta\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_eta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: get_th1_binning_np() takes 1 positional argument but 3 were given"
     ]
    }
   ],
   "source": [
    "filename = \"DeltaR_histograms_reco_NoCuts_output_mom_res_sigma_eta_5_p_6_B_3.0.root\"\n",
    "filename_14T=\"DeltaR_histograms_reco_NoCuts_output_mom_res_sigma_eta_5_p_6_B_1.4.root\"\n",
    "file = ROOT.TFile.Open(filename)\n",
    "\n",
    "\n",
    "eta_binning = {}\n",
    "eta_binning[\"edges\"],N_eta= TVT_to_numpy(file,\"TVT_eta_bin\")\n",
    "eta_binning[\"centers\"], eta_binning[\"widths\"] = get_binning_from_edges(eta_binning[\"edges\"])\n",
    "\n",
    "mom_binning = {}\n",
    "mom_binning[\"edges\"],N_mom = TVT_to_numpy(file,\"TVT_mom_bin\")\n",
    "mom_binning[\"centers\"], mom_binning[\"widths\"] = get_binning_from_edges(mom_binning[\"edges\"])\n",
    "\n",
    "N_mom = len(mom_binning[\"centers\"])\n",
    "N_eta = len(eta_binning[\"centers\"])\n",
    "\n",
    "eta_colors = get_colors(plt.cm.winter, N_eta)\n",
    "mom_colors = get_colors(plt.cm.autumn, N_mom)\n",
    "\n",
    "\n",
    "B_Fields = [1.4,3.0]\n",
    "B_Strings = [\"1p4\",\"3\"]\n",
    "N_divs = N_mom\n",
    "xlims=[[-0.04,0.04]]\n",
    "prefixes = [\"eDelta_dph\"] #Types of Resolutions\n",
    "\n",
    "h1dict = {}\n",
    "for B_String,B in zip(B_Strings,B_Fields):\n",
    "        if (B==1.4): \n",
    "            file = ROOT.TFile.Open(filename_14T)\n",
    "        if (B==3.0):\n",
    "            file = ROOT.TFile.Open(filename)\n",
    "        for s in prefixes:\n",
    "            h1dict[s+\"edges\"],h1dict[s+\"centers\"],h1dict[s+\"widths\"] = get_th1_binning_np(file.Get(\"eD_dph_histos/h1_eDelta_dph_p_et_bins_0_p_0_bin\",\"eD_dph_histos\")\n",
    "\n",
    "            for eta in range(N_eta):\n",
    "                for p in range(N_mom):\n",
    "                    identifier = (\"%s_B_%s_eta_%i_p_%i\"%(s,B_String,eta,p))\n",
    "                    h1dict[identifier+\"_vals\"],h1dict[identifier+\"_errors\"] = TH1_to_numpy_wErrors_old(file,\"h1_eDelta_dph_p_et_bins_%i_p_%i_bin\"%(eta,p),False,False,\"eD_dph_histos\")\n",
    "                    h1=file.Get(\"eD_dph_histos/\"+\"h1_eDelta_dph_p_et_bins_%i_p_%i_bin\"%(eta,p))\n",
    "                    h1dict[identifier+\"_avg\"] = h1.GetMean()\n",
    "                    h1dict[identifier+\"_sigma\"] = h1.GetStdDev()\n",
    "                    h1dict[identifier+\"_N\"] = h1.GetEntries() #For weighted averaging\n",
    "                    #print(h1.GetMean())\n",
    "                    \n",
    "np.save(\"./np_arrays/indv_histos.npy\",h1dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1908762a-24a3-465e-b10f-383323df4514",
   "metadata": {},
   "outputs": [],
   "source": [
    "string_selections = [\"../../output/reco_NoCuts_\"] #Reco Cuts. First two may not sum to 3rd\n",
    "\n",
    "for s,xlim in zip(prefixes,xlims):\n",
    "    for B_String,B in zip(B_Strings,B_Fields):\n",
    "        fig = plt.figure(figsize=(18,12))\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.title(r\"$\\Delta\\varphi$ Distributions (B = %1.1f T)\"%(B),fontsize=40,y=1.04,verticalalignment=\"bottom\")\n",
    "        i=0\n",
    "        for eta in range(N_eta):\n",
    "\n",
    "            for p in range(N_mom):\n",
    "                ax = fig.add_subplot(N_eta,N_divs,i+1)\n",
    "                i+=1\n",
    "                if eta==0:\n",
    "                    p_range_string = r\"$%1.1f < p < %1.1f$\"%(mom_binning[\"edges\"][p],mom_binning[\"edges\"][p+1])\n",
    "                    plt.text(0.5,1.18,p_range_string,ha=\"center\",va=\"top\",size=20,transform=ax.transAxes)\n",
    "                if p==0:\n",
    "                    eta_range_string = r\"$%1.1f < \\eta < %1.1f$\"%(eta_binning[\"edges\"][eta],eta_binning[\"edges\"][eta+1])\n",
    "                    #plt.text(0.5,1.12,eta_range_string,ha=\"center\",va=\"top\",size=15,alpha=0.7,transform=ax.transAxes)\n",
    "                    plt.ylabel(eta_range_string,fontsize=16)\n",
    "                for col in [\"r\",\"b\",\"g\"]:\n",
    "\n",
    "                    identifier = (\"%s_B_%s_eta_%i_p_%i\"%(s,B_String,eta,p))\n",
    "                    plt.errorbar(h1dict[s+\"centers\"],h1dict[identifier+\"_vals\"],yerr=h1dict[identifier+\"_errors\"],fmt=\".\",color=col,alpha=0.8)\n",
    "                    \n",
    "                    #aesthetics\n",
    "                    plt.xlim(xlim)\n",
    "                    plt.xticks(fontsize=8)\n",
    "                    plt.yticks(fontsize=8)\n",
    "                    mean = h1dict[identifier+\"_avg\"]\n",
    "                    #plt.axvline(x=h1dict[identifier+\"_avg\"],color=col,linestyle=\"--\",alpha=0.5)\n",
    "                    #stddev = h1dict[identifier+\"_sigma\"]\n",
    "                    #ax.axvspan(mean-stddev, mean+stddev, alpha=0.5, color=col)\n",
    "\n",
    "                    plt.text(0.98,0.95,\"B = %1.1f T\"%(B),ha=\"right\",va=\"top\",size=15,alpha=0.7,transform=ax.transAxes)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(s+\"_\"+B_String+\"_dDeltaPhi_Overlays.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f812c8-5733-4c49-af84-0cf084110786",
   "metadata": {},
   "source": [
    "# Compare Full and Charged Truth Jets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae756d73-c4ae-4cb8-b41b-f41a9baba685",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"../../output/reco_NoCuts_output_mom_res_3T_combinedsigma_eta_5_p_6_.root\"\n",
    "filename_14T=\"../../output/reco_NoCuts_output_mom_res_1p4T_combinedsigma_eta_5_p_6_.root\"\n",
    "file = ROOT.TFile.Open(filename)\n",
    "#file.ls()\n",
    "\n",
    "\n",
    "eta_binning = {}\n",
    "eta_binning[\"edges\"],N_eta= TVT_to_numpy(file,\"TVT_eta_bin\")\n",
    "eta_binning[\"centers\"], eta_binning[\"widths\"] = get_binning_from_edges(eta_binning[\"edges\"])\n",
    "\n",
    "mom_binning = {}\n",
    "mom_binning[\"edges\"],N_mom = TVT_to_numpy(file,\"TVT_mom_bin\")\n",
    "mom_binning[\"centers\"], mom_binning[\"widths\"] = get_binning_from_edges(mom_binning[\"edges\"])\n",
    "\n",
    "N_mom = len(mom_binning[\"centers\"])\n",
    "N_eta = len(eta_binning[\"centers\"])\n",
    "\n",
    "eta_colors = get_colors(plt.cm.winter, N_eta)\n",
    "mom_colors = get_colors(plt.cm.autumn, N_mom)\n",
    "\n",
    "\n",
    "B_Fields = [1.4,3.0]\n",
    "B_Strings = [\"1p4\",\"3\"]\n",
    "N_divs = N_mom\n",
    "xlims=[[-0.04,0.04]]\n",
    "prefixes = [\"efulljet_Delta_dph\"] #Types of Resolutions\n",
    "\n",
    "h1dict_full = {}\n",
    "for B_String,B in zip(B_Strings,B_Fields):\n",
    "        if (B==1.4): \n",
    "            file = ROOT.TFile.Open(filename_14T)\n",
    "        if (B==3.0):\n",
    "            file = ROOT.TFile.Open(filename)\n",
    "        for s in prefixes:\n",
    "            h1dict_full[s+\"edges\"],h1dict_full[s+\"centers\"],h1dict_full[s+\"widths\"] = get_th1_binning_np(file,\"h1_efulljet_Delta_dph_p_et_bins_0_p_0_bin\",\"eD_dph_histos\")\n",
    "\n",
    "            for eta in range(N_eta):\n",
    "                for p in range(N_mom):\n",
    "                    identifier = (\"%s_B_%s_eta_%i_p_%i\"%(s,B_String,eta,p))\n",
    "                    h1dict_full[identifier+\"_vals\"],h1dict_full[identifier+\"_errors\"] = TH1_to_numpy_wErrors_old(file,\"h1_efulljet_Delta_dph_p_et_bins_%i_p_%i_bin\"%(eta,p),False,False,\"eD_dph_histos\")\n",
    "                    h1=file.Get(\"eD_dph_histos/\"+\"h1_efulljet_Delta_dph_p_et_bins_%i_p_%i_bin\"%(eta,p))\n",
    "                    h1dict_full[identifier+\"_avg\"] = h1.GetMean()\n",
    "                    h1dict_full[identifier+\"_sigma\"] = h1.GetStdDev()\n",
    "                    #print(h1.GetMean())\n",
    "                    \n",
    "np.save(\"./np_arrays/indv_histos.npy\",h1dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfd669d-8bb1-45eb-a874-eea12df77a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "string_selections = [\"reco_NoCuts_\"] #Reco Cuts. First two may not sum to 3rd\n",
    "\n",
    "for s,xlim in zip(prefixes,xlims):\n",
    "    for B_String,B in zip(B_Strings,B_Fields):\n",
    "        fig = plt.figure(figsize=(18,12))\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.title(r\"Full/Charged $\\Delta\\varphi$ Distributions\",fontsize=40,y=1.04,verticalalignment=\"bottom\")\n",
    "        i=0\n",
    "        for eta in range(N_eta):\n",
    "\n",
    "            for p in range(N_mom):\n",
    "                ax = fig.add_subplot(N_eta,N_divs,i+1)\n",
    "                i+=1\n",
    "                if eta==0:\n",
    "                    p_range_string = r\"$%1.1f < p < %1.1f$\"%(mom_binning[\"edges\"][p],mom_binning[\"edges\"][p+1])\n",
    "                    plt.text(0.5,1.18,p_range_string,ha=\"center\",va=\"top\",size=20,transform=ax.transAxes)\n",
    "                if p==0:\n",
    "                    eta_range_string = r\"$%1.1f < \\eta < %1.1f$\"%(eta_binning[\"edges\"][eta],eta_binning[\"edges\"][eta+1])\n",
    "                    #plt.text(0.5,1.12,eta_range_string,ha=\"center\",va=\"top\",size=15,alpha=0.7,transform=ax.transAxes)\n",
    "                    plt.ylabel(eta_range_string,fontsize=16)\n",
    "                for col in [\"r\",\"b\",\"g\"]:\n",
    "\n",
    "                    identifier = (\"%s_B_%s_eta_%i_p_%i\"%(s,B_String,eta,p))\n",
    "                    plt.errorbar(h1dict_full[s+\"centers\"],h1dict_full[identifier+\"_vals\"],yerr=h1dict_full[identifier+\"_errors\"],fmt=\".\",color=col,alpha=0.8)\n",
    "                    \n",
    "                    #aesthetics\n",
    "                    plt.xlim(xlim)\n",
    "                    plt.xticks(fontsize=8)\n",
    "                    plt.yticks(fontsize=8)\n",
    "                    mean = h1dict_full[identifier+\"_avg\"]\n",
    "                    #plt.axvline(x=h1dict[identifier+\"_avg\"],color=col,linestyle=\"--\",alpha=0.5)\n",
    "                    #stddev = h1dict[identifier+\"_sigma\"]\n",
    "                    #ax.axvspan(mean-stddev, mean+stddev, alpha=0.5, color=col)\n",
    "\n",
    "                    plt.text(0.98,0.95,\"B = %1.1f T\"%(B),ha=\"right\",va=\"top\",size=15,alpha=0.7,transform=ax.transAxes)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(s+\"_\"+B_String+\"_fulljet_dDeltaPhi_Overlays.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5eb6bd9-510d-459c-8c55-90ba70b77f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "for eta in range (N_eta):\n",
    "    for p in range(N_mom):\n",
    "        B_String = \"3\"\n",
    "        s=\"eDelta_dph\"\n",
    "        identifier = (\"%s_B_%s_eta_%i_p_%i\"%(s,B_String,eta,p))\n",
    "        id_full=(\"%s_B_%s_eta_%i_p_%i\"%(\"efulljet_Delta_dph\",B_String,eta,p))\n",
    "        #print(h1dict[identifier+\"_errors\"][7],h1dict_full[id_full+\"_errors\"][7])\n",
    "\n",
    "#print(h1dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b32068-f5b0-479f-aedf-b70da415e99e",
   "metadata": {},
   "source": [
    "## Let's Fit in Python, because ROOT sucks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f5886a-9ea5-4fd4-8144-b07d65bc371f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set Fit Range for Single Gauss\n",
    "fit_min_value = -0.005\n",
    "fit_max_value = 0.005\n",
    "\n",
    "arr = h1dict[\"eDelta_dph\"+\"centers\"]\n",
    "min_array = np.absolute(arr-fit_min_value)\n",
    "max_array = np.absolute(arr-fit_max_value)\n",
    " \n",
    "min_index = np.argmin(min_array)\n",
    "max_index = np.argmin(max_array)+1\n",
    "\n",
    "B_Fields = [1.4,3.0]\n",
    "B_Strings = [\"1p4\",\"3\"]\n",
    "N_divs = N_mom\n",
    "xlims=[[-0.04,0.04]]\n",
    "prefixes = [\"eDelta_dph\"] #Types of Resolutions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e174f17-2a85-4f3d-b802-c79658bfe00e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Double Gauss Fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19ed5cf-eeaf-4cb9-ad94-c4c72a6dabdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "string_selections = [\"../../output/reco_NoCuts_\"] #Reco Cuts. First two may not sum to 3rd\n",
    "res_dict = {}\n",
    "\n",
    "for s,xlim in zip(prefixes,xlims):\n",
    "    for B_String,B in zip(B_Strings,B_Fields):\n",
    "        fig = plt.figure(figsize=(18,12))\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.title(r\"$\\Delta\\varphi$ Distributions (B = %1.1f T)\"%(B),fontsize=40,y=1.04,verticalalignment=\"bottom\")\n",
    "        i=0\n",
    "        for eta in range(N_eta):\n",
    "\n",
    "            for p in range(N_mom):\n",
    "                ax = fig.add_subplot(N_eta,N_divs,i+1)\n",
    "                i+=1\n",
    "                \n",
    "                if eta==0:\n",
    "                    p_range_string = r\"$%1.1f < p < %1.1f$\"%(mom_binning[\"edges\"][p],mom_binning[\"edges\"][p+1])\n",
    "                    plt.text(0.5,1.18,p_range_string,ha=\"center\",va=\"top\",size=20,transform=ax.transAxes)\n",
    "                if p==0:\n",
    "                    eta_range_string = r\"$%1.1f < \\eta < %1.1f$\"%(eta_binning[\"edges\"][eta],eta_binning[\"edges\"][eta+1])\n",
    "                    plt.ylabel(eta_range_string,fontsize=16)\n",
    "                \n",
    "                for col in [\"b\",\"r\",\"g\"]:\n",
    "\n",
    "                    identifier = (\"%s_B_%s_eta_%i_p_%i\"%(s,B_String,eta,p))\n",
    "                    plt.errorbar(h1dict[s+\"centers\"],h1dict[identifier+\"_vals\"],yerr=h1dict[identifier+\"_errors\"],fmt=\".\",color=col,alpha=0.8)\n",
    "                    ydata = h1dict[identifier+\"_vals\"]\n",
    "                    xdata=h1dict[s+\"centers\"]\n",
    "                    popt, pcov = curve_fit(double_gauss, xdata, ydata, p0=[ydata.max(), xdata.mean(), xdata.std()/4,ydata.max()/5,xdata.mean(),xdata.std()])\n",
    "                    plt.plot(xdata, double_gauss(xdata, *popt), 'r-', label='fit')\n",
    "                    res_dict[identifier+\"_dDeltaPhi_res\"] = popt[5] #narrow gauss sigma\n",
    "                    #aesthetics\n",
    "                    plt.xlim(xlim)\n",
    "                    plt.xticks(fontsize=8)\n",
    "                    plt.yticks(fontsize=8)\n",
    "                    \n",
    "                    plt.text(0.98,0.95,\"B = %1.1f T\"%(B),ha=\"right\",va=\"top\",size=15,alpha=0.7,transform=ax.transAxes)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(s+\"_\"+B_String+\"_dDeltaPhi_Overlays_Fits.pdf\")\n",
    "        print(popt[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc29ff11-68e2-4f18-82b5-41c8830ef210",
   "metadata": {},
   "source": [
    "### Weighted Average of Resolutions, to apply to $\\Delta$ R Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe514e41-ac9b-4404-abef-547d4103ce75",
   "metadata": {},
   "outputs": [],
   "source": [
    "for s,xlim in zip(prefixes,xlims):\n",
    "    for B_String,B in zip(B_Strings,B_Fields):\n",
    "        weighted_avg = 0\n",
    "        sum_N = 0\n",
    "        for eta in range(N_eta):            \n",
    "            for p in range(N_mom):\n",
    "                identifier = (\"%s_B_%s_eta_%i_p_%i\"%(s,B_String,eta,p))\n",
    "                #print(B,res_dict[identifier+\"_dDeltaPhi_res\"], h1dict[identifier+\"_N\"])\n",
    "                weighted_avg += res_dict[identifier+\"_dDeltaPhi_res\"]*h1dict[identifier+\"_N\"]\n",
    "                sum_N += h1dict[identifier+\"_N\"]\n",
    "        print(B,weighted_avg/sum_N)\n",
    "                \n",
    "#print(res_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9018adb9-cb40-4401-8989-3d9167982194",
   "metadata": {},
   "source": [
    "## e-Jet Correlations: Backward, Forward, and Central"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82275480-9ec1-41a0-b0f0-401e6e31b5ef",
   "metadata": {},
   "source": [
    "#### From e_Jet_Distributions.cxx:283"
   ]
  },
  {
   "cell_type": "raw",
   "id": "670080e4-3d79-4e6f-9952-1138f086c346",
   "metadata": {},
   "source": [
    "float eta_bin[] = {-3.0,-.5,0.5,3.0};//backward,central,forword\n",
    "const int size_eta_bin = sizeof(eta_bin)/sizeof(*eta_bin)-1;\n",
    "\n",
    "TH1F ** dPhiTj= new TH1F*[size_eta_bin];\n",
    "TH1F ** dPhiRj= new TH1F*[size_eta_bin];\n",
    "TH1F ** aT_edPhi= new TH1F*[size_eta_bin];\n",
    "\n",
    "for(int et = 0 ; et < size_eta_bin ; et++){\n",
    "    dPhiTj[et] = new TH1F(Form(\"dPhi_e_TrueJet_eta_%i\",et), \"|#Delta#varphi| (#varphi_{e} - #varphi^{True}_{Jet}) \", 128,0,M_PI);\n",
    "    dPhiRj[et] = new TH1F(Form(\"dPhi_e_RecoJet_eta_%i\",et), \"|#Delta#varphi| #varphi_{e} - #varphi(Jet^{Reco}_{Jet}) \", 128,0,M_PI);\n",
    "    aT_edPhi[et] = new TH1F(Form(\"all_dPhi_e_TrueJet_eta_%i\",et), \"|#Delta#varphi| (#varphi_{e} - #varphi^{True}_{Jet}) \", 128,0,M_PI);\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f5e2a5-3d74-49ec-b69e-d74309f3f32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"eta_bins_Histograms_Jet_Callibration_3.000000T.root\"\n",
    "filename_14T=\"eta_bins_Histograms_Jet_Callibration_1.400000T.root\"\n",
    "\n",
    "file = ROOT.TFile(filename)\n",
    "file_14T = ROOT.TFile(filename_14T)\n",
    "\n",
    "T_1p4 = {}\n",
    "T_3 = {}\n",
    "\n",
    "dPhi_bins,dPhi_centers,dPhi_widths = get_th1_binning_np(file,\"dPhi_e_TrueJet_eta_0\")\n",
    "\n",
    "\n",
    "for et in range(3):\n",
    "    TJ_dPhi, TJ_dPhi_errors = TH1_to_numpy_wErrors(file,\"dPhi_e_TrueJet_eta_%i\"%(et),False,False)\n",
    "    RJ_dPhi, RJ_dPhi_errors = TH1_to_numpy_wErrors(file,\"dPhi_e_RecoJet_eta_%i\"%(et),False,False)\n",
    "\n",
    "    Tesla14_RecodPhi,Tesla14_RecodPhi_errors = TH1_to_numpy_wErrors(file_14T,\"dPhi_e_RecoJet_eta_%i\"%(et),False,False)\n",
    "    Tesla14_TruthdPhi,Tesla14_TruthdPhi_errors = TH1_to_numpy_wErrors(file_14T,\"dPhi_e_TrueJet_eta_%i\"%(et),False,False)\n",
    "\n",
    "    all_TJ_dPhi, all_TJ_dPhi_errors = TH1_to_numpy_wErrors(file,\"all_dPhi_e_TrueJet_eta_%i\"%(et),False,False)\n",
    "\n",
    "    TJ_dPhi = TJ_dPhi/dPhi_widths\n",
    "    TJ_dPhi_errors = TJ_dPhi_errors/dPhi_widths\n",
    "    RJ_dPhi = RJ_dPhi/dPhi_widths\n",
    "    RJ_dPhi_errors = RJ_dPhi_errors/dPhi_widths\n",
    "\n",
    "    Tesla14_RecodPhi = Tesla14_RecodPhi/dPhi_widths\n",
    "    Tesla14_RecodPhi_errors = Tesla14_RecodPhi_errors/dPhi_widths \n",
    "    Tesla14_TruthdPhi = Tesla14_TruthdPhi/dPhi_widths\n",
    "    Tesla14_TruthdPhi_errors = Tesla14_TruthdPhi_errors/dPhi_widths\n",
    "\n",
    "    all_TJ_dPhi = all_TJ_dPhi/dPhi_widths\n",
    "    all_TJ_dPhi_errors = all_TJ_dPhi_errors/dPhi_widths\n",
    "    \n",
    "    T_1p4[\"truth_vals_eta_%i\"%(et)] = Tesla14_TruthdPhi\n",
    "    T_1p4[\"truth_err_eta_%i\"%(et)] = Tesla14_TruthdPhi_errors\n",
    "    T_1p4[\"reco_vals_eta_%i\"%(et)] = Tesla14_RecodPhi\n",
    "    T_1p4[\"reco_err_eta_%i\"%(et)] = Tesla14_TruthdPhi_errors\n",
    "    \n",
    "    T_3[\"all_truth_vals_eta_%i\"%(et)] = all_TJ_dPhi\n",
    "    T_3[\"all_truth_err_eta_%i\"%(et)] = all_TJ_dPhi_errors\n",
    "    \n",
    "    T_3[\"truth_vals_eta_%i\"%(et)] = TJ_dPhi\n",
    "    T_3[\"truth_err_eta_%i\"%(et)] = TJ_dPhi_errors\n",
    "    T_3[\"reco_vals_eta_%i\"%(et)] = RJ_dPhi\n",
    "    T_3[\"reco_err_eta_%i\"%(et)] = RJ_dPhi_errors\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba1ccfe-630a-46bb-80f0-37019df40002",
   "metadata": {},
   "outputs": [],
   "source": [
    "cool = get_colors(plt.cm.winter,4,False)\n",
    "\n",
    "for et in range(3):\n",
    "    \n",
    "    fig = plt.figure(figsize=(14,12))\n",
    "\n",
    "#3.0T Field\n",
    "    plt.errorbar(dPhi_centers,T_3[\"truth_vals_eta_%i\"%(et)],yerr=T_3[\"truth_err_eta_%i\"%(et)],\n",
    "                         fmt='-',color=cool[0],fillstyle='none',markersize=7,linewidth=3,\n",
    "                         label=r\"$|\\Delta\\varphi_\\mathrm{Truth}|~B = 3.0$ T\" )\n",
    "\n",
    "    plt.errorbar(dPhi_centers,T_3[\"reco_vals_eta_%i\"%(et)],yerr=T_3[\"reco_err_eta_%i\"%(et)],\n",
    "                         fmt='--',color=cool[1],linewidth=3,alpha=0.8,\n",
    "                         label=r\"$|\\Delta\\varphi_\\mathrm{Reco}|~B = 3.0$ T\" )\n",
    "\n",
    "#1.4T Field\n",
    "    plt.errorbar(dPhi_centers,T_1p4[\"truth_vals_eta_%i\"%(et)],yerr=T_1p4[\"truth_err_eta_%i\"%(et)],\n",
    "                         fmt='-',color=cool[2],fillstyle='none',markersize=7,linewidth=3,\n",
    "                         label=r\"$|\\Delta\\varphi_\\mathrm{Truth}|~B = 1.4$ T\" )\n",
    "                         #label=r\"$|\\varphi_{truth}^{jet} - \\varphi^{e}-\\pi|$\")\n",
    "\n",
    "    plt.errorbar(dPhi_centers,T_1p4[\"reco_vals_eta_%i\"%(et)],yerr=T_1p4[\"reco_err_eta_%i\"%(et)],\n",
    "                         fmt='--',color=cool[3],linewidth=3,alpha=0.8,\n",
    "                         label=r\"$|\\Delta\\varphi_\\mathrm{Reco}|~B = 1.4$ T\")\n",
    "                         #label=r\"$|\\varphi_{reco}^{jet} - \\varphi^{e}-\\pi|$\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.xlim(0,.5)\n",
    "    plt.ylabel(\"Raw Counts $\\mathrm{d}N/\\mathrm{d}\\Delta\\varphi$\",fontsize=25,y=0.5)\n",
    "    plt.xlabel(r\"$|\\Delta\\varphi|=|\\varphi^{jet} - \\varphi^{e}-\\pi|$\",fontsize=25,x=0.5)\n",
    "    plt.tick_params(which='both',direction='in',right=True,top=True,bottom=True,length=10,labelsize=20)\n",
    "    plt.legend(fontsize=25,loc='upper right')\n",
    "    plt.savefig(\"azimuthal_correlations_eta_bins.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e398f1-d415-41d9-a974-8a4d2a91bbdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90c1adb-8dd0-4a0a-84d6-39343bcb13f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
